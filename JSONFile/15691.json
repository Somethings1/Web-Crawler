{"summary":"If the viral Drake deep-fake brought you to this article, welcome to the fascinating (and admittedly spooky) side of how the Web3 music world is embracing artificial intelligence.","webName":"coindesk.com","link":"https:\/\/www.coindesk.com\/web3\/2023\/06\/06\/how-ai-is-transforming-music-creation-in-web3\/","publishDate":"2023-06-06T17:25:14","id":15691,"type":null,"title":"How AI is Transforming Music Creation in Web3","category":["Web3"],"content":["In April 2023, Warner Music Group chief digital officer and executive vice president of business development Oana Ruxandra told CoinDesk\u2019s The Hash that she expects music tools driven by artificial intelligence (AI) to \u201Copen up the world like we haven\u2019t before,\u201D inspiring \u201Cnew forms of creativity and sub-genres\u201D across the music and entertainment industries.","While Ruxandra\u2019s outlook is optimistic, she also acknowledged the concerns of many musicians: \u201CWe have to be very vigilant,\u201D she said, noting the importance of protecting the creativity and rights of artists. Just days before Ruxandra\u2019s appearance on The Hash, an AI-generated deep-fake music track titled Heart On My Sleeve gained traction by mimicking the voices of songwriters Drake and the Weeknd \u2013 even though neither artist had participated in its creation. Instead, the song\u2019s creators trained the artificial intelligence bot using music by the artists, which angered label owner Universal Music Group over.","Other musicians have been more welcoming to the new technology. Less than a week later, electropop musician Grimes invited her fans to create their own AI-dubbed songs using her voice and extended the offer to split royalties 50\/50, demonstrating one creative solution to the AI deep-fake conundrum.","Keeping intellectual property challenges in mind, there\u2019s still no doubt that AI music tools can place new forms of expression at an artist\u2019s fingertips. Sometimes, AI can even be used to enhance music production by filling in technical or intellectual gaps in an artist\u2019s abilities, helping them bring ambitious concepts to life in a matter of clicks. These tools can also perform sound engineering tasks more efficiently, lowering barriers and the time it takes to release music.","As we look toward Web3, companies and artists are taking AI even further by pairing music with immersive, interactive and user-generated experiences in the metaverse and beyond.","A number of crypto-native musicians and platforms have already found creative ways to integrate AI tools into their practice.","Take VNCCII, for instance, the metaverse-first alter-ego of Sydney-based female producer Samantha Tauber. Utilizing the industry-leading real-time 3D creation tool, Unreal Engine, Tauber dons her avatar to stream live broadcast interviews from the metaverse, in addition to performing in virtual concerts and shows. Like any set or costume change, the digital component of VNCCII\u2019s artistic identity is expanding the borders of her artistry.","Web3 music company PIXELNYX combines augmented reality (AR) experiences with metaverse gaming and is focused on helping artists build memorable experiences for fans. Co-founded by the electronic music producer Deadmau5, who has been known for sending fans on quests through The Sandbox and hosting shows in Decentraland, PIXELNYX aims to evolve our traditional notions of fandom through the use of AI, Web3 and user-generated content (UGC).","In April, PIXELNYX released Korus, a tool that allows users to create AI-powered music companions using officially-licensed artist content.","When used in this spirit, AI music tools can aid, augment or enhance an artist\u2019s creative style. While the tools are not good enough yet to replace artists, they are impressive and constantly \u201Clearning\u201D through continued human interaction. Replacing musicians with AI has never been a popular take, as proven by the pushback Spotify received after testing its own version of artificial music curation. Yet despite the controversy surrounding AI, today\u2019s musical artists may be able to benefit from using AI-assisted music production in ways that respect the craft.","WarpSound, an adaptive AI music platform, has found several ways to integrate blockchain-based collectibles and digital avatars into its business offerings. The company, which produces music content, non-fungible tokens (NFTs) and social experiences, is soon releasing a software API that composes original music note-by-note in a range of styles.","Founder and CEO Chris McGarry, an entrepreneur and media executive who previously severed as the music lead at Facebook\u2019s virtual reality unit Oculus, says WarpSound\u2019s tools help artists find new inspiration and source material that invigorates their creative processes. The company is the recipient of The Sandbox\u2019s Game Maker Fund, which supports game designers in The Sandbox metaverse, and plans to build a home venue inside the platform where artists can experiment with generative music.","WarpSound also worked with Mastercard as the AI music partner for their Artist Accelerator program, where McGarry says he\u2019s observed new benefits to the creative process.","\u201CLast week, I was in a set of virtual studio sessions with artists participating in the program,\u201D said McGarry. \u201CWe were working with our generative AI music interface to present a set of musical ideas, then having the artist shape those and iterate until they landed on something, the essence of which resonated with them, that they were motivated to work with.\u201D","WarpSound has also partnered with the Tribeca Film Festival and YouTube to create interactive and playful music experiences between artists and audiences.","If your music project is less about live performance and more about the finished product \u2014 maybe you\u2019re composing original music for a podcast, metaverse event, YouTube channel, Web3 video game or educational content \u2014 you can use AI to speed up the process of composition and arrangement. Of course, the world\u2019s most talented virtuosos can likely do musical scales in their sleep, but with so many elements to sound and video production, it\u2019s becoming standard practice to use AI to insert quick scales, arpeggios, runs and harmonies to original music.","Tools like Riffusion allow users to provide text prompts that are transformed into music. Soundful is another AI platform that allows people to generate and download royalty-free tracks.","If you want to go one step further and add lyrics, the popular do-it-all tool ChatGPT can write a two-verse song with a pre-chorus, chorus, bridge and outro in just under 30 seconds with minimal prompting. Of course, the lyrics may be a touch simplistic or cheesy \u2014 but aren\u2019t some of the best songs?","In most cases, songs generated by AI are reproducible without the need to pay licensing fees, given they were made by machines and therefore not protected under U.S. intellectual property law. Most platforms, however, charge a subscription fee.","These sounds can then be minted as NFTs and sold on marketplaces like OpenSea. Platforms like Royal.io also allow artists to join the site and offer their songs as fractionalized NFTs that offer royalty payouts to fans.","Read more: What Are Music NFTs?","You may have already heard that musical AI tools aren\u2019t yet that sophisticated, especially when compared to the latest AI text-to-image generators (which have already been used to spin out whole comic book collections) and Open AI\u2019s chatbot, Chat GPT (which reportedly passed the Bar exam).","Audio production indeed requires more computing power than static text and image outputs and therefore is lagging behind, according to experts in the field. Alexander Flores, head of tech and strategy at the music research network, Water & Music, says that tech innovation generally travels from the least data-intensive formats to the richest. In the case of AI, it makes sense why chatbots are perhaps faster to develop than AI audio and video rendering.","In one online discussion thread, a Reddit user pointed out these limitations, emphasizing that while a writer can proofread and edit an AI chatbot\u2019s outputs in seconds, it takes several minutes to listen to a song, and sometimes even hours to edit it. Machines are also slower to learn from AI datasets since audio files that feed them rarely have comprehensive text descriptions to teach the AI about the file\u2019s attributes (genre, tempo, key, instrumentation, etc.). Meanwhile, text and image-based AIs can swiftly trawl through thousands of words and visuals.","\u201CHow long it takes to consume the content matters a lot,\u201D said Flores. \u201CWith a song, you're locked in for three minutes. You can't speed it up because then you're not experiencing the actual song as it was written.\u201D","In addition, images are static, while songs are more dynamic: \u201CAudio is just much higher dimensional,\u201D said Stefan Lattner, managing researcher at Sony CSL, a creative technology lab, in a panel at Water & Music\u2019s inaugural Wavelengths Summit. \u201CWhile images have a fixed number of pixels, in audio you have a variable number of seconds that you want to generate.\u201D","Nonetheless, Water & Music calls creative AI the most disruptive technology for the music business since Napster, the peer-to-peer file-sharing application that made music distribution virtually free, as well as borderless and permissionless \u2013 a concept familiar to crypto-natives.","Edited by Rosie Perper."],"entity":[{"type":"April 2023","content":"DATE"},{"type":"Reddit","content":"LOCATION"},{"type":"U.S.","content":"LOCATION"},{"type":"Sydney","content":"LOCATION"},{"type":"UGC","content":"ORGANIZATION"},{"type":"Alexander Flores","content":"PERSON"},{"type":"Grimes","content":"PERSON"},{"type":"Tauber","content":"PERSON"},{"type":"Stefan Lattner","content":"PERSON"},{"type":"Unreal Engine","content":"ORGANIZATION"},{"type":"Drake","content":"PERSON"},{"type":"Napster","content":"ORGANIZATION"},{"type":"Tribeca Film Festival","content":"ORGANIZATION"},{"type":"April","content":"DATE"},{"type":"Chris McGarry","content":"PERSON"},{"type":"Oana Ruxandra","content":"ORGANIZATION"},{"type":"Mastercard","content":"ORGANIZATION"},{"type":"Korus","content":"PERSON"},{"type":"Sony CSL","content":"ORGANIZATION"},{"type":"Samantha Tauber","content":"PERSON"},{"type":"Warner Music Group","content":"ORGANIZATION"},{"type":"GPT","content":"ORGANIZATION"},{"type":"Universal Music Group","content":"ORGANIZATION"},{"type":"Water & Music\u2019s inaugural Wavelengths Summit","content":"ORGANIZATION"},{"type":"Water & Music","content":"ORGANIZATION"},{"type":"McGarry","content":"PERSON"},{"type":"Flores","content":"PERSON"},{"type":"Rosie Perper","content":"PERSON"},{"type":"Decentraland","content":"LOCATION"}],"hashtag":["NFTs","Beginner","Web3","Music","AI","Artificial Intelligence","NFT"],"authors":["Megan DeMatteo"]}