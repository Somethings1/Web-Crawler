{"summary":"Rag Bhagavatha and Chris McCoy are the co-creators of Storecoin Libra Blockchain overview Facebook yesterday unveiled its new low-volatility","webName":"theblock.co","link":"https:\/\/www.theblock.co\/post\/28194\/a-technical-perspective-on-facebooks-librabft-consensus-algorithm","publishDate":"2019-06-19T15:32:50","id":2680,"type":null,"title":"A technical perspective on Facebook\u2019s LibraBFT Consensus algorithm","category":["FACEBOOK"],"content":["<em data-v-f87c67ca=\"\"><a class=\"markup--anchor markup--p-anchor\" href=\"https:\/\/twitter.com\/storecoindev\" target=\"_blank\" rel=\"noopener noreferrer\" data-href=\"http:\/\/twitter.com\/storecoindev\" data-v-f87c67ca=\"\">Rag Bhagavatha<\/a> and <a class=\"markup--anchor markup--p-anchor\" href=\"https:\/\/twitter.com\/chrisamccoy\" target=\"_blank\" rel=\"noopener noreferrer\" data-href=\"http:\/\/twitter.com\/chrisamccoy\" data-v-f87c67ca=\"\">Chris McCoy<\/a> are the co-creators of <\/em><a class=\"markup--anchor markup--p-anchor\" href=\"http:\/\/storecoin.com\" target=\"_blank\" rel=\"noopener noreferrer\" data-href=\"http:\/\/storecoin.com\" data-v-f87c67ca=\"\"><em data-v-f87c67ca=\"\">Storecoin<\/em><\/a>","Facebook yesterday unveiled its new low-volatility cryptocurrency Libra, powered by a smart contract platform that\u2019s designed to be \u201Csecure, scalable, and reliable\u201D.","Libra Blockchain uses a robust and efficient state machine replication system called LibraBFT [1], which is the focus of this technical analysis. We discuss its properties and compare it to other Byzantine Fault Tolerant (BFT) consensus protocols with similar properties.","Consensus is a process used to achieve <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">agreement<\/em> on a single data value among distributed processes or systems. The processes participating in the consensus may or may not trust each other and yet, they will be able to arrive at an agreement on a single data value. There are two classes of consensus algorithms.","Classical consensus algorithms satisfy the following general properties.","<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">Validity<\/strong>\u200A\u2014\u200AIf a correct process <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">p<\/strong> broadcasts a message <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m<\/strong>, then <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">p<\/strong> eventually delivers <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m<\/strong>.","<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">Agreement\u200A<\/strong>\u2014\u200AIf a message <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m<\/strong> is delivered by some correct process, then <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m<\/strong> is eventually delivered by every correct process.","<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">Integrity<\/strong>\u200A\u2014\u200ANo correct process delivers the same message more than once; moreover, if a correct process delivers a message <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m<\/strong> and the sender<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"> p<\/strong> of <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m<\/strong> is correct, then <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m<\/strong> was previously broadcast by <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">p<\/strong>.","<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">Total order<\/strong>\u200A\u2014\u200AFor messages <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m1<\/strong> and <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m2<\/strong>, suppose <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">p<\/strong> and <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">q<\/strong> are two correct processes that deliver <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m1<\/strong> and <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m2<\/strong>. Then <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">p<\/strong> delivers <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m1<\/strong> before <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m2<\/strong> if and only if <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">q<\/strong> delivers <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m1<\/strong> before <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">m2<\/strong>.","When a network of disparate processes participate in a consensus process, failures occur. For example, processes may crash, experience power and network failures, or simply be unable to make progress because they are stuck in a certain state. These are generally classified as <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">crash failures<\/em>. On the other hand, some processes may intentionally act maliciously to steer the consensus to their benefit. Such failures are called Byzantine failures. Consensus algorithms that tolerate Byzantine failures are called Byzantine Fault Tolerant (BFT) algorithms. BFT consensus algorithms are also capable of handling crash failures automatically.","The network of processes participating in the consensus process can be configured in permissioned or permissionless setups.","Libra Blockchain will be configured as a <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">permissioned network<\/em> at launch with a known set of processes called <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">Validators<\/em>. This means, all Validators in the Libra network know each other\u2019s identities.","LibraBFT belongs to the class of classical BFT consensus algorithms. It is based on another consensus algorithm called HotStuff [2], which in turn borrows some of its consensus logic from yet another classical BFT algorithm called Practical Byzantine Fault Tolerance, pBFT [3].","pBFT uses a system model, which assumes an asynchronous distributed system where processes are connected by a network. The network may fail to deliver messages, delay them, duplicate them, or deliver them out of order. If <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">N<\/strong> is the total number of processes in the network and <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">f<\/strong> is the number of faulty (including Byzantine) processes, then pBFT requires:","<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">N ≥ 3f + 1<\/strong>","processes to provide tolerance against Byzantine failures.","pBFT consensus algorithm makes progress in multiple rounds, where each round accomplishes agreement on some stage in the consensus process. Fig. 1 illustrates pBFT consensus rounds, which proceed as follows.","Fig. 1\u200A\u2014\u200ApBFT consensus rounds","The protocol makes progress and guarantees <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"><em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">liveness<\/em><\/strong>, if the leader doesn\u2019t fail. In case of leader failures, a <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">view-change<\/em> protocol is triggered after a <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">timeout<\/em> to prevent the replicas from waiting forever for messages from the leader. In a geographically distributed asynchronous network, leader failures may be more common than one can imagine, so view-change triggers may also be commonplace. So, the execution complexity of pBFT with view-changes is O(<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">n<\/strong>3) where <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">n<\/strong> is the number of processes in the network.","The protocol provides <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"><em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">safety<\/em><\/strong> if all non-faulty replicas compute the same result. This means (<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">N-f<\/strong>) processes must compute the same result and send the results to the client to guarantee safety.","HotStuff consensus algorithm attempts to address the O(<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">n<\/strong>3) complexity of pBFT. The <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"><em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">liveness<\/em><\/strong> property requires that (<strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">N−f<\/strong>) non-faulty replicas will run commands identically and produce the same response for each command. As is common, with the partially synchronous communication model, whereby a known bound\u200A\u2014\u200A∆\u200A\u2014\u200Aon message transmission holds after some unknown global stabilization time (GST). In this model, <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">N ≥ 3f + 1 <\/strong>is required for non-faulty replicas to agree on the same commands in the same order and progress can be ensured deterministically only after GST as we have discussed earlier with view-changes. HotStuff improves upon pBFT with the following two additional properties.","Table-1 below shows the resulting improvements in the message complexity. With the correct leader, the complexity improved from O(n2) to O(n). With leader failure and the resulting view-change protocol, the complexity improved from O(n3) to O(n).","Table 1\u200A\u2014\u200AComparison of message complexities of some classical BFT consensus algorithms","In pBFT each round in the consensus performs similar work (like, collecting votes from replicas etc.), which HotStuff optimizes by chaining <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">Quorum Certificates<\/em> (QC) as shown in fig. 2. With this the consensus rounds can be chained, thus improving the <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"><em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">liveness<\/em><\/strong>. <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">k<\/strong> view-changes requires <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">k+2<\/strong> rounds of communication instead of <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">2*k<\/strong>.","Fig. 2\u200A\u2014\u200AChained HotStuff","HotStuff also implements a mechanism called <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">Pacemaker<\/em>, that guarantees liveness after GST. Pacemaker a) synchronizes all correct replicas and a unique leader into a common height for a sufficiently long period of time. It chooses the unique leader such that the correct replicas synchronized will make progress with the chosen leader. This mechanism decouples <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"><em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">liveness<\/em><\/strong> from the protocol, which in turn decouples it from <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"><em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">safety<\/em><\/strong>.","LibraBFT improves upon HotStuff with a detailed specification and implementation of the Pacemaker mechanism discussed above. It also comes with a liveness analysis that consists of concrete bounds to transaction commitment. Other than these enhancements, LibraBFT is essentially HotStuff and makes the same assumptions about the system model with a partially synchronous network.","In LibraBFT processes are called Validators and they make progress in rounds, each having a designated validator called a <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">leader<\/em>. Leaders are responsible for proposing new blocks and obtaining signed votes from the validators on their proposals. LibraBFT follows the Chained HotStuff model described in fig. 2, which works as follows.","The above consensus process can be compared with another popular classical BFT consensus algorithm, Tendermint [4], which is illustrated in fig. 3.","Fig. 3\u200A\u2014\u200ATendermint consensus process","Like LibraBFT, Tendermint proceeds in multiple rounds\u200A\u2014\u200Apre-vote, pre-commit, and commit\u200A\u2014\u200Aand collects Validator signatures for each round, similar to the QCs in LibraBFT. The main difference between the two algorithms is that in Tendermint each round has a timeout and the Validators wait even if they finish the round sooner whereas in LibraBFT, once the network is synchronous, the protocol speed is based on the network latency, <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\">as long as the leader is correct<\/strong>.","The qualification highlighted above is important. The protocol terminates without having to wait for a timeout, only if the leader is correct. If the leader fails, the view-change protocol triggers after GST and while the view-change is <em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">linear<\/em> and is optimized when compared to pBFT, it may not perform any better than Tendermint\u2019s implementation.","Libra Blockchain is launched as a permissioned network. The founding Validators include the likes of Uber, Visa, MasterCard, PayPal, etc. Founding members are required to meet strict guidelines to be part of the early Validator set. For instance, crypto hedge funds had to have an AUM above $1 billion while digital asset-focused custodians had to store at least $100 million. Non-crypto firms needed to have a market cap of more than $1 billion or boast customer balances equaling more than $500 million. With such stringent requirements in place, one can assume that the Validators will more likely be run in data centers with private or highly reliable networking connecting them. They are likely be fault tolerant, similar to the setup required to run Cosmos Validators (which run Tendermint consensus algorithm). So practically speaking, Chained HotStuff will likely be the only important design that improves the <strong class=\"markup--strong markup--p-strong\" data-v-f87c67ca=\"\"><em class=\"markup--em markup--p-em\" data-v-f87c67ca=\"\">liveness<\/em><\/strong> of the protocol. All other design improvements may be less useful in the practical deployment described above. On the other hand, if the network is assumed to be unreliable, the assumptions made about the correctness of leaders for fast termination may in fact fail, resulting in worst case performance.","© 2023 The Block. All Rights Reserved. This article is provided for informational purposes only. It is not offered or intended to be used as legal, tax, investment, financial, or other advice."],"entity":[{"type":"AUM","content":"ORGANIZATION"},{"type":"GST","content":"ORGANIZATION"},{"type":"$500 million","content":"MONEY"},{"type":"MasterCard","content":"ORGANIZATION"},{"type":"$1 billion","content":"MONEY"},{"type":"$100 million","content":"MONEY"},{"type":"2023","content":"DATE"},{"type":"PayPal","content":"ORGANIZATION"},{"type":"Chris McCoy","content":"PERSON"},{"type":"1","content":"DATE"},{"type":"Tendermint","content":"LOCATION"}],"hashtag":[],"authors":["Contributor Network","The Block"]}